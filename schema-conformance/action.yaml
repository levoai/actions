name: "Levo Conformance Action"
description: "Run Levo conformance tests in your Github workflows"
inputs:
  schema:
    description: 'URL or path to the OAS schema file'
    required: true
  target:
    description: 'Target URL to the unit under test'
    required: true
  authorization-key:
    description: 'Authorization key for CLI to run. Get it from https://app.levo.ai/settings/keys'
    required: true
  organization-id:
    description: 'Levo Organization ID'
    required: true
  fail-on-failed-tests:
    description: 'Fail action on failed test cases. Default: true'
    required: true
    default: true
  saas-url:
    description: 'Saas url to report results back'
    required: true
    default: "https://api.levo.ai"
  report:
    description: 'Report schema conformance run result to Saas'
    required: false
    default: true
  cli_extra_args:
    description: 'CLI extra arguments. E.g: -H "Authorization: Bearer 123'
    required: false
    default: ""
outputs:
  success:
    description: 'Succeded test cases'
    value: ${{ steps.run-conformance-test.outputs.success }}
  failed:
    description: 'Failed test cases'
    value: ${{ steps.run-conformance-test.outputs.failed }}
runs:
  using: 'composite'
  steps:
    - id: run-conformance-test
      run: |
        # Enable aliases since this is non-interactive shell
        shopt -s expand_aliases
        export LOCAL_UID=`id -u`
        export LOCAL_GID=`id -g`
        mkdir $PWD/reports
        alias levo="sudo docker run --rm --add-host=host.docker.internal:`ip route|awk '/docker0/ { print $9 }'` --mount type=bind,source=$HOME/.config/configstore,target=/home/levo/.config/configstore -v $PWD:/home/levo/work:rw -e LEVO_BASE_URL=${{ inputs.saas-url }} -e LOCAL_USER_ID=$LOCAL_UID -e LOCAL_GROUP_ID=$LOCAL_GID -e TERM=xterm-256color -t levoai/levo"
        levo login -k ${{ inputs.authorization-key }} -o ${{ inputs.organization-id }}
        set +e
        CMD='levo test-conformance --schema "${{ inputs.schema }}" --target-url "${{ inputs.target }}"'
        if ${{ inputs.report != 'true' }}; then
          CMD=$(echo $CMD --disable-reporting-to-saas)
        fi
        CMD=$(echo $CMD ${{ inputs.cli_extra_args }} --export-junit-xml=/home/levo/work/reports/junit.xml)
        echo Running: $CMD
        eval $CMD | tee /tmp/conformance.log
        ls -all
        SUCCESS=$(grep -oEi "[0-9]+ passed, [0-9]+ failed" /tmp/conformance.log | grep -oEi "[0-9]+ passed" | grep -oEi "[0-9]+")
        FAILED=$(grep -oEi "[0-9]+ passed, [0-9]+ failed" /tmp/conformance.log | grep -oEi "[0-9]+ failed" | grep -oEi "[0-9]+")
        echo "::set-output name=success::$(echo $SUCCESS)"
        echo "::set-output name=failed::$(echo $FAILED)"
      shell: bash
    # - uses: mikepenz/action-junit-report@v3.5.0
    #   if: always() # always run even if the previous step fails
    #   with:
    #     report_paths: '**/reports/*.xml'
    #     commit: ${{github.event.workflow_run.head_sha}}
    #     fail_on_failure: ${{ inputs.fail-on-failed-tests }}
    #     detailed_summary: true
    - id: reporting
      run: |
        if ${{ inputs.fail-on-failed-tests == 'true' }}; then
          echo "::set-output name=fail_on::$(echo 'test failures')"
        fi
        if ${{ inputs.fail-on-failed-tests != 'true' }}; then
          echo "::set-output name=fail_on::$(echo 'nothing')"
        fi
      shell: bash
    - name: Publish Test Results
      if: always()
      uses: EnricoMi/publish-unit-test-result-action@v2
      with:
        junit_files: '**/reports/*.xml'
        fail_on: ${{ steps.reporting.outputs.fail_on }}
        check_run_annotations: 'none'
        check_name: "Levo Schema Conformance Results"
