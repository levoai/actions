name: "Levo Conformance Action"
description: "Run Levo conformance tests in your Github workflows"
inputs:
  schema:
    description: 'URL or path to the OAS schema file'
    required: true
  target:
    description: 'Target URL to the unit under test'
    required: true
  authorization-key:
    description: 'Authorization key for CLI to run. Get it from https://app.levo.ai/settings/keys'
    required: true
  organization-id:
    description: 'Levo Organization ID'
    required: true
  fail-on-failed-tests:
    description: 'Fail action on failed test cases. Default: true'
    required: true
    default: true
  saas-url:
    description: 'Saas url to report results back'
    required: true
    default: "https://api.levo.ai"
  report:
    description: 'Report schema conformance run result to Saas'
    required: false
    default: true
  cli_extra_args:
    description: 'CLI extra arguments. E.g: -H "Authorization: Bearer 123'
    required: false
    default: ""
outputs:
  success:
    description: 'Succeded test cases'
    value: ${{ steps.map-outputs.outputs.success }}
  failed:
    description: 'Failed test cases'
    value: ${{ steps.map-outputs.outputs.failed }}
  error:
    description: 'Errored test cases'
    value: ${{ steps.map-outputs.outputs.error }}
  skipped:
    description: 'Skipped test cases'
    value: ${{ steps.map-outputs.outputs.skip }}
  total:
    description: 'Total test cases'
    value: ${{ steps.map-outputs.outputs.total }}
runs:
  using: 'composite'
  steps:
    - id: run-conformance-test
      run: |
        # Enable aliases since this is non-interactive shell
        shopt -s expand_aliases
        export LOCAL_UID=`id -u`
        export LOCAL_GID=`id -g`
        mkdir $PWD/reports
        alias levo="sudo docker run --rm --add-host=host.docker.internal:`ip route|awk '/docker0/ { print $9 }'` --mount type=bind,source=$HOME/.config/configstore,target=/home/levo/.config/configstore -v $PWD:/home/levo/work:rw -e LEVO_BASE_URL=${{ inputs.saas-url }} -e LOCAL_USER_ID=$LOCAL_UID -e LOCAL_GROUP_ID=$LOCAL_GID -e TERM=xterm-256color -t levoai/levo"
        levo login -k ${{ inputs.authorization-key }} -o ${{ inputs.organization-id }}
        set +e
        CMD='levo test-conformance --schema "${{ inputs.schema }}" --target-url "${{ inputs.target }}"'
        if ${{ inputs.report != 'true' }}; then
          CMD=$(echo $CMD --disable-reporting-to-saas)
        fi
        CMD=$(echo $CMD ${{ inputs.cli_extra_args }} --export-junit-xml=/home/levo/work/reports/junit.xml)
        echo Running: $CMD
        eval $CMD
        exit 0
      shell: bash
    - id: reporting
      if: always()
      run: |
        if ${{ inputs.fail-on-failed-tests == 'true' }}; then
          echo "::set-output name=fail_on::$(echo 'test failures')"
        fi
        if ${{ inputs.fail-on-failed-tests != 'true' }}; then
          echo "::set-output name=fail_on::$(echo 'nothing')"
        fi
      shell: bash
    - name: Publish Test Results
      id: publish-junit
      if: always()
      uses: EnricoMi/publish-unit-test-result-action@v2
      with:
        junit_files: '**/reports/*.xml'
        fail_on: ${{ steps.reporting.outputs.fail_on }}
        check_run_annotations: 'none'
        check_name: "Levo Schema Conformance Results"
    - id: map-outputs
      if: always()
      run: |
        echo "success=${{ fromJSON(steps.publish-junit.outputs.json).stats.tests_succ }}" >> $GITHUB_OUTPUT
        echo "failed=${{ fromJSON(steps.publish-junit.outputs.json).stats.tests_fail }}" >> $GITHUB_OUTPUT
        echo "error=${{ fromJSON(steps.publish-junit.outputs.json).stats.tests_error }}" >> $GITHUB_OUTPUT
        echo "skip=${{ fromJSON(steps.publish-junit.outputs.json).stats.tests_skip }}" >> $GITHUB_OUTPUT
        echo "total=${{ fromJSON(steps.publish-junit.outputs.json).stats.tests }}" >> $GITHUB_OUTPUT
      shell: bash
